#!/bin/sh
#SBATCH --job-name=p4_all_study_sim   # Job name
#SBATCH --mail-type=ALL         # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=craut+csg@umich.edu # Where to send mail	
#SBATCH --nodes=1                   # Use one node
#SBATCH --ntasks=1                  # Run a single task
#SBATCH --mem-per-cpu=1gb           # Memory per processor
#SBATCH --time=09:00:00             # Time limit hrs:min:sec
#SBATCH --output=array_%A-%a.out    # Standard output and error log
#SBATCH --array=1-779               # Array range
# This is an example script that combines array tasks with
# bash loops to process many short runs. Array jobs are convenient
# for running lots of tasks, but if each task is short, theycd 
# quickly become inefficient, taking more time to schedule than
# they spend doing any work and bogging down the scheduler for
# all users. 

pwd; hostname; date

# Set the number of runs that each SLURM task should do
# This is equivalent to how many seeds I should go through for each exp setting
PER_TASK=1000

# get to my profile
source ~/.bash_profile
# get to the place of action
ACTION=~/Courses/BS699/P4/Project4
cd $ACTION

# Print the task and run range
read -r N_NON_RESP N_RESP  <<< "$(sed -n $SLURM_ARRAY_TASK_ID'p' $ACTION/params.txt)"
N_OBS=$(($N_NON_RESP + $N_RESP))

# who is this, what is this doing
echo This is task $SLURM_ARRAY_TASK_ID, which will do $PER_TASK sims with patients = $N_OBS \& responders = $N_RESP

# Run the loop of runs for this task.
START_NUM=1;
END_NUM=$(($START_NUM + $PER_TASK));
for (( run=$START_NUM; run<END_NUM; run++ )); do
  echo This is SLURM task $SLURM_ARRAY_TASK_ID, run number $run
  read -r SEED  <<< "$(sed -n $run'p' $ACTION/seeds.txt)"
  echo using seed: $SEED
  outdir=$ACTION/slurm/out/sim_size/nobs_$N_OBS/nresp_$N_RESP/
  mkdir -p $outdir
  Rscript --slave $ACTION/simul.R --n_obs $N_OBS --n_resp $N_RESP --seed $SEED > $outdir$SEED.out 2> $outdir$SEED.err
done

date
